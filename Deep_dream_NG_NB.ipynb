{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Final Script.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dr4gonAndroidDev/DeepDreamVideoProccessing/blob/main/Deep_dream_NG_NB.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7luKREyamrqW",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "outputId": "22cdb372-df01-4f4d-c434-4d1d70ab276e"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LoAFOPDMm1rr",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "bec658c8-4cd7-462e-835a-7dfe91717bb7"
      },
      "source": [
        "cd gdrive"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pqAv51wLm6CC",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "59c4232b-2b18-4404-9ef8-a00ae0f4ce31"
      },
      "source": [
        "cd My Drive"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/gdrive/My Drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "es5b4ajnnGJf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "1d432230-cccc-4b76-cf35-ea83809f63c2"
      },
      "source": [
        "cd Deep\\ Dream\\ Video\\ Processing "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/gdrive/My Drive/Deep Dream Video Processing\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hwfnjzConH4L",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        },
        "outputId": "bbe6d188-2bdb-4081-cfd0-567ed90b99a5"
      },
      "source": [
        "!ls"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "'best outputs'\t\t\t     frames_video_3\n",
            "'Copy of Deep Dream.ipynb'\t     imp_functions.py\n",
            "'Copy of TestScript.ipynb'\t     inception\n",
            " Deep_Dream_Video_Processing.ipynb   inception5h.py\n",
            " download.py\t\t\t     music\n",
            " final_output2\t\t\t     Output\n",
            "'Final Output Deep Dream.ipynb'      Output_cleaner\n",
            "'final outputs'\t\t\t    'Output of all images'\n",
            "'Final Script_enhanced3.ipynb'\t     __pycache__\n",
            "'Final Script.ipynb'\t\t     tensorflow_inception_graph.pb\n",
            " footage\t\t\t    'TestScript (1).ipynb'\n",
            " frames\t\t\t\t     TestScript.ipynb\n",
            " frames_video_2\t\t\t    'trimmed footage'\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_dxFQSOW4f2g"
      },
      "source": [
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FtW5sY0EY87c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 63
        },
        "outputId": "ddd4f39d-33f6-4c1d-be5a-730e3a0eecd0"
      },
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import random\n",
        "import math\n",
        "from imp_functions import *\n",
        "import inception5h\n",
        "import glob\n",
        "\n",
        "# Image manipulation.\n",
        "from PIL import Image\n",
        "from scipy.ndimage.filters import gaussian_filter"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ci_4p1TvcsAK",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "c8bbe3f0-5c14-4bba-d7dd-b7715c648b29"
      },
      "source": [
        "inception5h.maybe_download()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading Inception 5h Model ...\n",
            "Data has apparently already been downloaded and unpacked.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w-hNBF__JGd4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "outputId": "efa9c5ed-6ab7-40d0-cf7d-e49098812d91"
      },
      "source": [
        "model = inception5h.Inception5h()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /content/gdrive/My Drive/Deep Dream Video Processing/inception5h.py:97: FastGFile.__init__ (from tensorflow.python.platform.gfile) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.gfile.GFile.\n",
            "WARNING:tensorflow:From /content/gdrive/My Drive/Deep Dream Video Processing/inception5h.py:100: The name tf.GraphDef is deprecated. Please use tf.compat.v1.GraphDef instead.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LTdOeFh2JG_U",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "17ac71ab-45f9-4403-c6d8-995b22487c06"
      },
      "source": [
        "len(model.layer_tensors)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "12"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "636APEkoJO9K"
      },
      "source": [
        "def load_image(filename):\n",
        "    original = Image.open(filename)\n",
        "    return np.float32(original)\n",
        "\n",
        "def save_image(image, filename):\n",
        "    # Ensure the pixel-values are between 0 and 255.\n",
        "    image = np.clip(image, 0.0, 255.0)\n",
        "    \n",
        "    # Convert to bytes.\n",
        "    image = image.astype(np.uint8)\n",
        "    \n",
        "    # Write the image-file in jpeg-format.\n",
        "    with open(filename, 'wb') as file:\n",
        "        Image.fromarray(image).save(file, 'jpeg')\n",
        "\n",
        "def plot_image(image):\n",
        "    # Assume the pixel-values are scaled between 0 and 255.\n",
        "    \n",
        "    if False:\n",
        "        # Convert the pixel-values to the range between 0.0 and 1.0\n",
        "        image = np.clip(image/255.0, 0.0, 1.0)\n",
        "        \n",
        "        # Plot using matplotlib.\n",
        "        plt.imshow(image, interpolation='lanczos')\n",
        "        plt.show()\n",
        "    else:\n",
        "        # Ensure the pixel-values are between 0 and 255.\n",
        "        image = np.clip(image, 0.0, 255.0)\n",
        "        \n",
        "        # Convert pixels to bytes.\n",
        "        image = image.astype(np.uint8)\n",
        "\n",
        "        # Convert to a PIL-image and display it.\n",
        "        display(Image.fromarray(image))\n",
        "\n",
        "def normalize_image(x):\n",
        "    # Get the min and max values for all pixels in the input.\n",
        "    x_min = x.min()\n",
        "    x_max = x.max()\n",
        "\n",
        "    # Normalize so all values are between 0.0 and 1.0\n",
        "    x_norm = (x - x_min) / (x_max - x_min)\n",
        "    \n",
        "    return x_norm\n",
        "\n",
        "def plot_gradient(gradient):\n",
        "    # Normalize the gradient so it is between 0.0 and 1.0\n",
        "    gradient_normalized = normalize_image(gradient)\n",
        "    \n",
        "    # Plot the normalized gradient.\n",
        "    plt.imshow(gradient_normalized, interpolation='bilinear')\n",
        "    plt.show()\n",
        "\n",
        "def resize_image(image, size=None, factor=None):\n",
        "    # If a rescaling-factor is provided then use it.\n",
        "    if factor is not None:\n",
        "        # Scale the numpy array's shape for height and width.\n",
        "        size = np.array(image.shape[0:2]) * factor\n",
        "        \n",
        "        # The size is floating-point because it was scaled.\n",
        "        # PIL requires the size to be integers.\n",
        "        size = size.astype(int)\n",
        "    else:\n",
        "        # Ensure the size has length 2.\n",
        "        size = size[0:2]\n",
        "    \n",
        "    # The height and width is reversed in numpy vs. PIL.\n",
        "    size = tuple(reversed(size))\n",
        "\n",
        "    # Ensure the pixel-values are between 0 and 255.\n",
        "    img = np.clip(image, 0.0, 255.0)\n",
        "    \n",
        "    # Convert the pixels to 8-bit bytes.\n",
        "    img = img.astype(np.uint8)\n",
        "    \n",
        "    # Create PIL-object from numpy array.\n",
        "    img = Image.fromarray(img)\n",
        "    \n",
        "    # Resize the image.\n",
        "    img_resized = img.resize(size, Image.LANCZOS)\n",
        "    \n",
        "    # Convert 8-bit pixel values back to floating-point.\n",
        "    img_resized = np.float32(img_resized)\n",
        "\n",
        "    return img_resized\n",
        "\n",
        "def get_tile_size(num_pixels, tile_size=400):\n",
        "    \"\"\"\n",
        "    num_pixels is the number of pixels in a dimension of the image.\n",
        "    tile_size is the desired tile-size.\n",
        "    \"\"\"\n",
        "\n",
        "    # How many times can we repeat a tile of the desired size.\n",
        "    num_tiles = int(round(num_pixels / tile_size))\n",
        "    \n",
        "    # Ensure that there is at least 1 tile.\n",
        "    num_tiles = max(1, num_tiles)\n",
        "    \n",
        "    # The actual tile-size.\n",
        "    actual_tile_size = math.ceil(num_pixels / num_tiles)\n",
        "    \n",
        "    return actual_tile_size\n",
        "\n",
        "def tiled_gradient(gradient, image, tile_size=400):\n",
        "    # Allocate an array for the gradient of the entire image.\n",
        "    grad = np.zeros_like(image) # zeros like returns an array of the same shape and type as the image\n",
        "\n",
        "    # Number of pixels for the x- and y-axes.\n",
        "    x_max, y_max, _ = image.shape\n",
        "\n",
        "    # Tile-size for the x-axis.\n",
        "    x_tile_size = get_tile_size(num_pixels=x_max, tile_size=tile_size)\n",
        "    # 1/4 of the tile-size.\n",
        "    x_tile_size4 = x_tile_size // 4\n",
        "\n",
        "    # Tile-size for the y-axis.\n",
        "    y_tile_size = get_tile_size(num_pixels=y_max, tile_size=tile_size)\n",
        "    # 1/4 of the tile-size\n",
        "    y_tile_size4 = y_tile_size // 4\n",
        "\n",
        "    # Random start-position for the tiles on the x-axis.\n",
        "    # The random value is between -3/4 and -1/4 of the tile-size.\n",
        "    # This is so the border-tiles are at least 1/4 of the tile-size,\n",
        "    # otherwise the tiles may be too small which creates noisy gradients.\n",
        "    x_start = random.randint(-3*x_tile_size4, -x_tile_size4)\n",
        "\n",
        "    while x_start < x_max:\n",
        "        # End-position for the current tile.\n",
        "        x_end = x_start + x_tile_size\n",
        "        \n",
        "        # Ensure the tile's start- and end-positions are valid.\n",
        "        x_start_lim = max(x_start, 0)\n",
        "        x_end_lim = min(x_end, x_max)\n",
        "\n",
        "        # Random start-position for the tiles on the y-axis.\n",
        "        # The random value is between -3/4 and -1/4 of the tile-size.\n",
        "        y_start = random.randint(-3*y_tile_size4, -y_tile_size4)\n",
        "\n",
        "        while y_start < y_max:\n",
        "            # End-position for the current tile.\n",
        "            y_end = y_start + y_tile_size\n",
        "\n",
        "            # Ensure the tile's start- and end-positions are valid.\n",
        "            y_start_lim = max(y_start, 0)\n",
        "            y_end_lim = min(y_end, y_max)\n",
        "\n",
        "            # Get the image-tile.\n",
        "            img_tile = image[x_start_lim:x_end_lim,\n",
        "                             y_start_lim:y_end_lim, :]\n",
        "\n",
        "            # Create a feed-dict with the image-tile.\n",
        "            feed_dict = model.create_feed_dict(image=img_tile)\n",
        "\n",
        "            # Use TensorFlow to calculate the gradient-value.\n",
        "            g = session.run(gradient, feed_dict=feed_dict)\n",
        "\n",
        "            # Normalize the gradient for the tile. This is\n",
        "            # necessary because the tiles may have very different\n",
        "            # values. Normalizing gives a more coherent gradient.\n",
        "            g /= (np.std(g) + 1e-8)\n",
        "\n",
        "            # Store the tile's gradient at the appropriate location.\n",
        "            grad[x_start_lim:x_end_lim,\n",
        "                 y_start_lim:y_end_lim, :] = g\n",
        "            \n",
        "            # Advance the start-position for the y-axis.\n",
        "            y_start = y_end\n",
        "\n",
        "        # Advance the start-position for the x-axis.\n",
        "        x_start = x_end\n",
        "\n",
        "    return grad\n",
        "\n",
        "def optimize_image(layer_tensor, image,\n",
        "                   num_iterations=10, step_size=3.0, tile_size=400):\n",
        "    \"\"\"\n",
        "    Use gradient ascent to optimize an image so it maximizes the\n",
        "    mean value of the given layer_tensor.\n",
        "\n",
        "    Parameters:\n",
        "    layer_tensor: Reference to a tensor that will be maximized.\n",
        "    image: Input image used as the starting point.\n",
        "    num_iterations: Number of optimization iterations to perform.\n",
        "    step_size: Scale for each step of the gradient ascent.\n",
        "    tile_size: Size of the tiles when calculating the gradient.\n",
        "    show_gradient: Plot the gradient in each iteration.\n",
        "    \"\"\"\n",
        "\n",
        "    # Copy the image so we don't overwrite the original image.\n",
        "    img = image.copy()\n",
        "\n",
        "    # Use TensorFlow to get the mathematical function for the\n",
        "    # gradient of the given layer-tensor with regard to the\n",
        "    # input image. This may cause TensorFlow to add the same\n",
        "    # math-expressions to the graph each time this function is called.\n",
        "    # It may use a lot of RAM and could be moved outside the function.\n",
        "    gradient = model.get_gradient(layer_tensor)\n",
        "\n",
        "    for i in range(num_iterations):\n",
        "        # Calculate the value of the gradient.\n",
        "        # This tells us how to change the image so as to\n",
        "        # maximize the mean of the given layer-tensor.\n",
        "        grad = tiled_gradient(gradient=gradient, image=img)\n",
        "\n",
        "        # Blur the gradient with different amounts and add\n",
        "        # them together. The blur amount is also increased\n",
        "        # during the optimization. This was found to give\n",
        "        # nice, smooth images. You can try and change the formulas.\n",
        "        # The blur-amount is called sigma (0=no blur, 1=low blur, etc.)\n",
        "        # We could call gaussian_filter(grad, sigma=(sigma, sigma, 0.0))\n",
        "        # which would not blur the colour-channel. This tends to\n",
        "        # give psychadelic / pastel colours in the resulting images.\n",
        "        # When the colour-channel is also blurred the colours of the\n",
        "        # input image are mostly retained in the output image.\n",
        "        sigma = (i * 4.0) / num_iterations + 0.5\n",
        "        grad_smooth1 = gaussian_filter(grad, sigma=sigma)\n",
        "        grad_smooth2 = gaussian_filter(grad, sigma=sigma*2)\n",
        "        grad_smooth3 = gaussian_filter(grad, sigma=sigma*0.5)\n",
        "        grad = (grad_smooth1 + grad_smooth2 + grad_smooth3)\n",
        "\n",
        "        # Scale the step-size according to the gradient-values.\n",
        "        # This may not be necessary because the tiled-gradient\n",
        "        # is already normalized.\n",
        "        step_size_scaled = step_size / (np.std(grad) + 1e-8)\n",
        "\n",
        "        # Update the image by following the gradient.\n",
        "        img += grad * step_size_scaled\n",
        "\n",
        "    return img\n",
        "\n",
        "def recursive_optimize(layer_tensor, image,\n",
        "                       num_repeats=4, rescale_factor=0.7, blend=0.2,\n",
        "                       num_iterations=10, step_size=3.0,\n",
        "                       tile_size=400):\n",
        "    \"\"\"\n",
        "    Recursively blur and downscale the input image.\n",
        "    Each downscaled image is run through the optimize_image()\n",
        "    function to amplify the patterns that the Inception model sees.\n",
        "\n",
        "    Parameters:\n",
        "    image: Input image used as the starting point.\n",
        "    rescale_factor: Downscaling factor for the image.\n",
        "    num_repeats: Number of times to downscale the image.\n",
        "    blend: Factor for blending the original and processed images.\n",
        "\n",
        "    Parameters passed to optimize_image():\n",
        "    layer_tensor: Reference to a tensor that will be maximized.\n",
        "    num_iterations: Number of optimization iterations to perform.\n",
        "    step_size: Scale for each step of the gradient ascent.\n",
        "    tile_size: Size of the tiles when calculating the gradient.\n",
        "    \"\"\"\n",
        "\n",
        "    # Do a recursive step?\n",
        "    if num_repeats>0:\n",
        "        # Blur the input image to prevent artifacts when downscaling.\n",
        "        # The blur amount is controlled by sigma. Note that the\n",
        "        # colour-channel is not blurred as it would make the image gray.\n",
        "        sigma = 0.5\n",
        "        img_blur = gaussian_filter(image, sigma=(sigma, sigma, 0.0))\n",
        "\n",
        "        # Downscale the image.\n",
        "        img_downscaled = resize_image(image=img_blur,\n",
        "                                      factor=rescale_factor)\n",
        "            \n",
        "        # Recursive call to this function.\n",
        "        # Subtract one from num_repeats and use the downscaled image.\n",
        "        img_result = recursive_optimize(layer_tensor=layer_tensor,\n",
        "                                        image=img_downscaled,\n",
        "                                        num_repeats=num_repeats-1,\n",
        "                                        rescale_factor=rescale_factor,\n",
        "                                        blend=blend,\n",
        "                                        num_iterations=num_iterations,\n",
        "                                        step_size=step_size,\n",
        "                                        tile_size=tile_size)\n",
        "        \n",
        "        # Upscale the resulting image back to its original size.\n",
        "        img_upscaled = resize_image(image=img_result, size=image.shape)\n",
        "\n",
        "        # Blend the original and processed images.\n",
        "        image = blend * image + (1.0 - blend) * img_upscaled\n",
        "\n",
        "    # Process the image using the DeepDream algorithm.\n",
        "    img_result = optimize_image(layer_tensor=layer_tensor,\n",
        "                                image=image,\n",
        "                                num_iterations=num_iterations,\n",
        "                                step_size=step_size,\n",
        "                                tile_size=tile_size)\n",
        "    \n",
        "\n",
        "    return img_result"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gRraV3X47pLK"
      },
      "source": [
        "images = glob.glob('frames_video_2/*.jpg') "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PpM1LCDgs7qu"
      },
      "source": [
        "images.sort()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TU0B_sDqtNik",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "748c0852-afe7-4539-c889-93ccb4f1c0fa"
      },
      "source": [
        "finished = glob.glob('final outputs/*.jpg')\n",
        "len(finished)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "101"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "66u8Ph55SEoU"
      },
      "source": [
        "images_batch1 = images[101:]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YWmmxeKT8o1D",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "daa5bddb-6ab8-4ac2-e05a-0bccc91da747"
      },
      "source": [
        "len(images)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "179"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A7IEaSj7S8l4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "1868ca84-8ec1-431a-dd90-cb4bc8124a6d"
      },
      "source": [
        "len(images_batch1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "78"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pfQ4ySKbDyIq",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "3533d0d3-a8b4-4c07-97c5-72fd166e828e"
      },
      "source": [
        "learning_rate = []\n",
        "\n",
        "n = 0\n",
        "n_max = 3.0\n",
        "by = 0.25\n",
        "\n",
        "for num in range(0, len(images)):\n",
        "    while n < n_max:\n",
        "        n+=by\n",
        "        learning_rate.append(n)\n",
        "    while n > 0:\n",
        "        n-=by\n",
        "        learning_rate.append(n)\n",
        "\n",
        "learning_rate = learning_rate[0:len(images)]\n",
        "learning_rate = np.array(learning_rate)\n",
        "learning_rate[-1] = n_max\n",
        "len(learning_rate)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "179"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SBtVAnjgEkcU",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 306
        },
        "outputId": "1d2a42df-566a-4a1a-d8a8-0e8e55adfc56"
      },
      "source": [
        "learning_rate"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.25, 0.5 , 0.75, 1.  , 1.25, 1.5 , 1.75, 2.  , 2.25, 2.5 , 2.75,\n",
              "       3.  , 2.75, 2.5 , 2.25, 2.  , 1.75, 1.5 , 1.25, 1.  , 0.75, 0.5 ,\n",
              "       0.25, 0.  , 0.25, 0.5 , 0.75, 1.  , 1.25, 1.5 , 1.75, 2.  , 2.25,\n",
              "       2.5 , 2.75, 3.  , 2.75, 2.5 , 2.25, 2.  , 1.75, 1.5 , 1.25, 1.  ,\n",
              "       0.75, 0.5 , 0.25, 0.  , 0.25, 0.5 , 0.75, 1.  , 1.25, 1.5 , 1.75,\n",
              "       2.  , 2.25, 2.5 , 2.75, 3.  , 2.75, 2.5 , 2.25, 2.  , 1.75, 1.5 ,\n",
              "       1.25, 1.  , 0.75, 0.5 , 0.25, 0.  , 0.25, 0.5 , 0.75, 1.  , 1.25,\n",
              "       1.5 , 1.75, 2.  , 2.25, 2.5 , 2.75, 3.  , 2.75, 2.5 , 2.25, 2.  ,\n",
              "       1.75, 1.5 , 1.25, 1.  , 0.75, 0.5 , 0.25, 0.  , 0.25, 0.5 , 0.75,\n",
              "       1.  , 1.25, 1.5 , 1.75, 2.  , 2.25, 2.5 , 2.75, 3.  , 2.75, 2.5 ,\n",
              "       2.25, 2.  , 1.75, 1.5 , 1.25, 1.  , 0.75, 0.5 , 0.25, 0.  , 0.25,\n",
              "       0.5 , 0.75, 1.  , 1.25, 1.5 , 1.75, 2.  , 2.25, 2.5 , 2.75, 3.  ,\n",
              "       2.75, 2.5 , 2.25, 2.  , 1.75, 1.5 , 1.25, 1.  , 0.75, 0.5 , 0.25,\n",
              "       0.  , 0.25, 0.5 , 0.75, 1.  , 1.25, 1.5 , 1.75, 2.  , 2.25, 2.5 ,\n",
              "       2.75, 3.  , 2.75, 2.5 , 2.25, 2.  , 1.75, 1.5 , 1.25, 1.  , 0.75,\n",
              "       0.5 , 0.25, 0.  , 0.25, 0.5 , 0.75, 1.  , 1.25, 1.5 , 1.75, 2.  ,\n",
              "       2.25, 2.5 , 3.  ])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fgeTTz4cE6PY"
      },
      "source": [
        "import re\n",
        "pattern = '\\d+'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "daPR8uiEGiLj"
      },
      "source": [
        "layer_tensor = model.layer_tensors[6]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D3YVPBDm8wcX",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "68d01e23-b16c-4cfc-f216-17956a61ef60"
      },
      "source": [
        "# replace image_batch1 when needed:\n",
        "for image in images_batch1:\n",
        "  idx = int(re.findall(pattern, image.split('/')[1])[0])\n",
        "  # Tensorflow Session\n",
        "  session = tf.InteractiveSession(graph=model.graph)\n",
        "  image=load_image(filename=image)\n",
        "  img_result = recursive_optimize(layer_tensor=layer_tensor, image=image,\n",
        "                 num_iterations=10, step_size=learning_rate[idx], rescale_factor=0.7,\n",
        "                 num_repeats=4, blend=0.2)\n",
        "  save_image(img_result, f'final outputs/final_output_image_frame_{idx}.jpg')\n",
        "  print(f'Finished processing Image: {idx}')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Finished processing Image: 29\n",
            "Finished processing Image: 3\n",
            "Finished processing Image: 30\n",
            "Finished processing Image: 31\n",
            "Finished processing Image: 32\n",
            "Finished processing Image: 33\n",
            "Finished processing Image: 34\n",
            "Finished processing Image: 35\n",
            "Finished processing Image: 36\n",
            "Finished processing Image: 37\n",
            "Finished processing Image: 38\n",
            "Finished processing Image: 39\n",
            "Finished processing Image: 4\n",
            "Finished processing Image: 40\n",
            "Finished processing Image: 41\n",
            "Finished processing Image: 42\n",
            "Finished processing Image: 43\n",
            "Finished processing Image: 44\n",
            "Finished processing Image: 45\n",
            "Finished processing Image: 46\n",
            "Finished processing Image: 47\n",
            "Finished processing Image: 48\n",
            "Finished processing Image: 49\n",
            "Finished processing Image: 5\n",
            "Finished processing Image: 50\n",
            "Finished processing Image: 51\n",
            "Finished processing Image: 52\n",
            "Finished processing Image: 53\n",
            "Finished processing Image: 54\n",
            "Finished processing Image: 55\n",
            "Finished processing Image: 56\n",
            "Finished processing Image: 57\n",
            "Finished processing Image: 58\n",
            "Finished processing Image: 59\n",
            "Finished processing Image: 6\n",
            "Finished processing Image: 60\n",
            "Finished processing Image: 61\n",
            "Finished processing Image: 62\n",
            "Finished processing Image: 63\n",
            "Finished processing Image: 64\n",
            "Finished processing Image: 65\n",
            "Finished processing Image: 66\n",
            "Finished processing Image: 67\n",
            "Finished processing Image: 68\n",
            "Finished processing Image: 69\n",
            "Finished processing Image: 7\n",
            "Finished processing Image: 70\n",
            "Finished processing Image: 71\n",
            "Finished processing Image: 72\n",
            "Finished processing Image: 73\n",
            "Finished processing Image: 74\n",
            "Finished processing Image: 75\n",
            "Finished processing Image: 76\n",
            "Finished processing Image: 77\n",
            "Finished processing Image: 78\n",
            "Finished processing Image: 79\n",
            "Finished processing Image: 8\n",
            "Finished processing Image: 80\n",
            "Finished processing Image: 81\n",
            "Finished processing Image: 82\n",
            "Finished processing Image: 83\n",
            "Finished processing Image: 84\n",
            "Finished processing Image: 85\n",
            "Finished processing Image: 86\n",
            "Finished processing Image: 87\n",
            "Finished processing Image: 88\n",
            "Finished processing Image: 89\n",
            "Finished processing Image: 9\n",
            "Finished processing Image: 90\n",
            "Finished processing Image: 91\n",
            "Finished processing Image: 92\n",
            "Finished processing Image: 93\n",
            "Finished processing Image: 94\n",
            "Finished processing Image: 95\n",
            "Finished processing Image: 96\n",
            "Finished processing Image: 97\n",
            "Finished processing Image: 98\n",
            "Finished processing Image: 99\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OpFX7SGvmp69"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}